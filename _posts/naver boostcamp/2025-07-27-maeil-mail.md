---
layout: single
title: "[프로젝트 회고] MaeilMail - 일간 메일 보고서 비서 (Naver boostcamp)"
date: 2025-07-29 08:56:00 +0900
categories: naver-boostcamp
---

더 이상 미룰 수 없었던 매일메일 프로젝트에 대한 회고를 남긴다.
나는 단순한 챗봇이 아니라, 정말 사람들에게 실질적인 도움을 줄 수 있는 **LLM 기반 서비스**를 만들고 싶었다.
그 방향성 아래, 우리 팀은 **하루 동안 받은 이메일을 요약 및 정리해주는 LLM Agent 시스템**을 기획했고, 이를 **Chrome Extension** 형태로 구현했다.

매일메일은 네이버 부스트캠프 7기 최종 기업 연계 프로젝트로, **Upstage**와 함께 진행되었다.

연하게 보여줄 수 있는 LLM Agent 시스템\*\*을 크롬 익스텐션을 통해 제작하였다.

[![Demo](/assets/images/2025/07/29/demo.png)](https://jagaldol.com/projects/maeil-mail)

> [Maeil Mail Github Repo](https://github.com/jagaldol/maeilmail)  
> [Maeil Mail 프로젝트 소개 포트폴리오(jagaldol.com)](https://jagaldol.com/projects/maeil-mail)

## 팀 결성

나는 부스트캠프 7기 NLP 트랙에 참여하며, 최종 프로젝트를 위해 새로운 팀을 꾸렸다.  
처음 배정된 팀은 랜덤 매칭이었는데, 각자의 목표(대학원 진학, 연구, 서비스 개발 등)가 너무 달라 뜻을 모으기 어려웠다.

리빌딩 시기가 되자, 미리 눈여겨봤던 몇몇 캠퍼들에게 직접 연락을 했고, 결국 정말 이상적인 팀을 구성할 수 있었다.

우리 팀의 가장 큰 강점은, 열정적이고 소통이 잘 되는 분위기였다.  
부스트캠프는 온라인 기반이지만, 원하는 팀은 수내 교육장을 오프라인으로 이용할 수 있다.
우리 6인 팀 중 지방 거주자는 나(부산)를 포함해 3명이었는데, 이 3명이 모두 수내역 근처 고시원으로 올라와 **2개월간 합숙을 하며 개발**을 함께 했다!

> 이전까지 오프라인 개발 동아리 경험이 없던 나로서는, 매일 같이 팀원들과 모여 토의하고 개발하는 시간이 너무 소중했다.
>
> 수료 후에도 나는 계속 고시원에 머물며 취업 준비를 했고, 결국 Upstage 인턴으로 합격하며 탈출하게 되었다!

## 기업 해커톤 Upstage 주제 선정

이렇게 모인 우리 팀은 **제대로 된 LLM 기반 서비스를 End-to-End로 개발해보고 싶다**는 공통된 목표가 있었다.

따라서 자유롭게 Solar 모델을 활용할 수 있었던 기업인 Upstage와 함께 해커톤을 진행하기로 결정했고, **생산성을 높이는 실용적인 도구**라는 방향성 아래 **MaeilMail Agent**를 기획하게 되었다.

## 아이디어 후보 - Virtual YouTuber

주제를 정하던 초기, 다양한 아이디어가 오갔고 그중 가장 유력했던 후보 중 하나가 바로 **LLM 기반 Virtual YouTuber**였다.
LLM이 버튜버로 동작하며 실시간 채팅과 슈퍼챗 등 시청자와 상호작용하는 구조였고, 나아가 **AI 캐릭터들끼리 대화하며 방송을 이어가는 형태**까지도 아이디어가 나왔었다.

하지만 구현 난이도와 운영 부담이 상당히 높았고, 현실적인 한계로 인해 자연스럽게 채택되지 못했다.

이후 XAI의 Grok에서 **Ani**라는 AI Companion 캐릭터가 실제로 등장해 화제가 되었고, 우리 아이디어와 유사한 방향성이었다는 점에서 아쉬움이 들었다.

이번 경험을 통해, **아이디어를 아이디어로만 남겨두면 결국 누군가가 먼저 실현한다는 교훈**도 얻을 수 있었다.

> 일론 머스크도 정말 대단한 사람이다. 어떻게 저걸 Grok 공식 앱에 구현할 생각을 하지?

## 서비스 기획

업무 생산성 도구인 만큼, 사용자 경험(UX)을 가장 먼저 고려했다.

메일 확인이라는 귀찮은 루틴을 줄이기 위한 서비스인데, 이를 위해 별도의 웹페이지나 앱에 접속해야 한다면 오히려 불편을 가중시킬 수 있다.
그래서 기존 Gmail을 사용하던 사람들이 별도의 진입장벽 없이 자연스럽게 사용할 수 있도록, **Chrome Extension 형태**로 서비스를 기획하게 되었다.

![Demo](/assets/images/2025/07/29/demo.png)

위 이미지는 실제 확장 프로그램의 UI이다.

사용자는 Gmail 페이지를 벗어나지 않고도, 해당 확장 프로그램을 통해 요약된 메일 보고서를 바로 확인할 수 있다.
이는 중요한 메일을 놓치지 않도록 도와주고, 수십 통의 메일을 효율적으로 정리하여 **확인 시간을 단축**하는 데 기여한다.

### 서비스 플로우

서비스의 핵심 플로우는 아래와 같다.

1. 사용자는 서비스에 가입한다. (Google OAuth 2.0 기반)
2. 매일 오전, 유저가 전날 수신한 이메일들을 가져와 LLM을 통해 요약, 분류, 정리를 수행한다.
    - 유저의 페르소나는 대학원생으로 설정되어 있으며, 메일은 학술연구 / 행정처리 / 기타로 분류된다.
    - 유사한 이메일은 clustering되어 묶인다.
3. 완성된 보고서를 형식에 맞춰 DB에 저장한다.
4. 유저는 확장 프로그램을 통해 해당 리포트를 확인할 수 있다.
    - 중요한 메일을 빠르게 찾거나, 전체 내용을 한눈에 요약해 파악할 수 있다.

### 시스템 구조

최종 구현된 시스템의 아키텍처는 아래와 같다.

![pipeline](/assets/images/2025/07/29/pipeline.png)

Chrome Extension을 통해 여러 사용자가 동시에 서비스를 이용할 수 있으며, 실제 AI 비즈니스 로직은 서버 단에서 처리된다.
자세한 AI 파이프라인 내용은 아래 '개발' 파트에서 설명한다.

### 개발 일정

아래는 전체 개발 일정을 정리한 타임라인이다.

![timeline](/assets/images/2025/07/29/timeline.png)

## 서비스 개발

본격적인 서비스를 개발하기 위해서는 부스트캠프에서 학습한 AI와 LLM 역량뿐만 아니라, 웹과 서버 개발에 대한 경험도 요구되었다. 그런데 우리 팀에서 해당 역량을 갖춘 사람은 나뿐이었고, 자연스럽게 관련 전반을 맡게 되었다.

팀원들 모두 AI 분야 취업을 목표로 하고 있었기에, 리소스를 가능한 한 AI 파이프라인 개발에 집중하려 했다. 따라서 웹과 서버 개발은 MVP 수준으로 기능을 제한하고 최소한의 구현으로 진행했다.

### Chrome Extension + FastAPI

확장 프로그램과 백엔드 서버 구축은 프로젝트 초기부터 내가 단독으로 개발했다. 웹 프로젝트는 이전에도 경험이 많았지만, 확장 프로그램 개발은 처음이어서 시행착오가 많았다. 특히, OAuth 2.0을 활용해 사용자의 Gmail 메일함에 접근하는 과정에서 보안 관련 이슈를 해결하는 데 많은 시간을 쏟았다.

그럼에도 불구하고, 목표했던 핵심 기능들은 모두 안정적으로 구현할 수 있었고, 최소한의 MVP 수준으로 완성된 결과물을 만들 수 있었다.

> 예전부터 단순한 웹페이지를 넘어서 실제로 유용한 브라우저 확장 프로그램을 만들어보고 싶었는데, 이번 프로젝트를 통해 그 기회를 잡을 수 있었다.

### AI Agent Business Pipeline

서비스의 핵심은 웹 UI가 아닌, 매일 수신된 이메일을 요약하여 보고서 형태로 정리하는 **LLM 기반 파이프라인**이다.

매일 아침, 등록된 사용자들의 Gmail 메일함에서 새로운 이메일 목록을 수집하고, 이를 기반으로 Agent가 작동하여 각 사용자의 Daily Report를 생성하고 DB에 저장한다.

![ai logic](/assets/images/2025/07/29/agent-pipeline.png)

우선, 스팸·광고 등 불필요한 메일은 Rule-Based 방식으로 1차 필터링한다.  
이후 남은 메일들을 LLM 입력에 적합하도록 변환해야 하는데, 이 과정에서는 Upstage의 Document Parser를 사용하여 메일을 구조화된 텍스트 형식으로 정제한다.

정제된 각 이메일은 개별적으로 요약되며, 이때 **Self Refine 루프**와 **Solar 기반 Groundedness Check**를 통해 잘못된 요약이 생성되지 않도록 보완한다.

이메일 단위 요약이 끝나면, 모든 요약을 종합해 하루치 메일 보고서를 생성한다. 이 단계에서는 **Reflexion 기법**을 적용하여 반복적인 개선을 수행하며 보고서의 품질을 끌어올린다.

완성된 최종 보고서는 개별 메일 요약 정보를 기준으로 분류 및 클러스터링된 형태로 저장되며, Chrome 확장 프로그램을 통해 사용자에게 제공된다.

> 초기에는 메일 전체를 한 번에 처리하는 구조를 구상했으나, 토큰 사용량이 과도하게 높아졌고 비용 문제로 이어졌다.  
> 이에 따라 먼저 개별 요약을 수행한 뒤, 이를 기반으로 보고서를 생성하는 구조로 전환하게 되었다.  
> 핵심 로직은 Self Refine과 Reflexion이며, 나는 Reflexion 구현을 주도했다.

### Self Refine

각 이메일을 핵심 정보를 포함하고 있는 요약문으로 만드는 self refine 루프이다.

![self refine](/assets/images/2025/07/29/self-refine.png)

먼저 Solar 모델이 요약문을 생성한 뒤, **Groundedness Check**를 통해 할루시네이션 여부를 검증하고, 요약문 내 개선점을 찾기 위한 **Feedback**을 생성한다.  
이 피드백을 바탕으로 요약을 개선하며, 이 과정을 최대 3회까지 반복하여 최적의 결과를 도출한다.

### Reflexion

각 이메일 요약문들을 모아 최종 보고서를 만드는 reflexion 루프이다.

![reflexion](/assets/images/2025/07/29/reflexion.png)

Self Refine과의 가장 큰 차이점은, Reflexion에서는 별도의 **Evaluator**가 존재한다는 점이다.
Evaluator는 보고서를 다각도로 평가한 후 점수를 매기고, 이를 기반으로 Reflector가 개선 방향을 수립하여 피드백을 생성한다.

또한, 이 구조에서는 **Long-Term Memory**를 활용해 최초 생성부터 최종 버전까지의 전체 변경 흐름을 기억하고, 일관성 있게 개선할 수 있다.

단, Reflexion은 많은 토큰을 소모하기 때문에 비용이 높다. 따라서 개별 이메일 요약에는 Self Refine을 적용하고, Reflexion은 최종 보고서 생성에만 사용했다.

우리 팀은 Evaluator로 G-Eval 방식을 참고해 평가 기준을 설계했고, 평가 모델로는 Solar를 사용했다.
평가 기준에 따라 점수를 산출한 후, 이를 최대화할 수 있는 방향으로 반복 개선을 수행한 결과, 평균 점수를 3.75점에서 4.19점(4.5점 만점)까지 향상시킬 수 있었다. 덕분에 항상 일정 수준 이상의 고품질 보고서를 생성할 수 있었다.

> Reflexion의 개념이 재밌어서 논문도 열심히 읽고 즐겁게 구현했었다. 나중에 시간이 나면 해당 논문도 리뷰를 남기고자 한다.

## 결과

### 📝 개별 메일 요약

| Condition              | ROUGE-1 Recall | ROUGE-1 Precision | ROUGE-1 F1 | BERT Score Recall | BERT Score Precision | BERT Score F1 | G-EVAL Conciseness |
| ---------------------- | -------------- | ----------------- | ---------- | ----------------- | -------------------- | ------------- | ------------------ |
| Baseline               | 0.0667         | 0.0042            | 0.1678     | 0.8223            | 0.8789               | 0.8494        | 4.3958             |
| + refine               | 0.2618         | 0.2049            | 0.4649     | 0.8740            | 0.9146               | 0.8932        | 4.8750             |
| + one-shot             | 0.2288         | 0.2005            | 0.3661     | 0.8325            | 0.8905               | 0.8588        | 4.9375             |
| **+ refine, one-shot** | **0.3062**     | **0.2691**        | **0.4690** | **0.8905**        | **0.9319**           | **0.9107**    | **4.9167**         |

`ROUGE-1`에서 **24.0 ~ 30.1%p**, `BERTScore`에서 **5.3 ~ 6.8%p**, `G-Eval conciseness` 항목(5점 만점)에서 **0.52점** 상승하였다.

### 📜 최종 리포트

| Condition                                                 | G-eval score |
| --------------------------------------------------------- | ------------ |
| Self-Refine: Baseline                                     | 3.75         |
| Self-Refine: Detailed Instructions                        | 3.50         |
| Self-Refine: Detailed Instructions + Formatting Penalty   | 3.94         |
| Reflexion: Baseline                                       | 4.00         |
| Reflexion: Detailed Instructions                          | 3.50         |
| **Reflexion: Detailed Instructions + Formatting Penalty** | **4.19**     |

`G-Eval` 평가 평균 점수(4.5점 만점)에서 **0.44점** 상승하였다.

## 회고

반년간의 부스트캠프 여정을 마무리하는 프로젝트였기에, 정말 모든 시간을 쏟아부어 개발에 임했다.  
특히 수내 고시원에서 함께 생활한 팀원 2명과는 주말에도 카페에서 노트북을 펴고 밤새 프로젝트 회의를 이어가며, 끝까지 완성도를 높이고자 함께 달려주었다.  
이렇게 자발적으로 몰입할 수 있는 팀을 새롭게 구성한 것은, 이번 프로젝트에서 가장 잘한 선택 중 하나였다.

AI 분야는 신입으로 취업하기 어려운 환경이지만, 우리 팀은 다행히도 나를 포함해 2명이 취직을 하였고, 또 다른 한 명은 KAIST 대학원에 입학했다.  
특히 나는 이번 프로젝트를 통해 Upstage 부스트캠프 전형에 지원해 인턴으로 합격하여, 현재 근무 중이다.

아쉬웠던 점도 있었다.  
웹 개발을 전담한 사람이 나뿐이었기 때문에, 제한된 시간 속에서 프론트/백엔드 구현 범위를 확장하기 어려웠다.  
또한 AI 파이프라인이 잦은 변경을 겪으면서 API 병렬 호출이나 매일 아침 실행되는 배치 처리 등 일부 기능이 충분히 테스트되지 못해, 정식 출시에는 이르지 못한 점이 아쉽다.

이러한 부분들을 개선해, 나중에 시간이 난다면 전체 구조를 리빌딩하여 개인적으로라도 실사용 가능한 서비스로 발전시켜보고 싶다.

---

이전까지는 LLM 기반 챗봇 프로젝트만 진행했었는데, 이번에는 메일 요약 보고서라는 **새로운 형태의 LLM 서비스**를 설계하고 직접 구현하며, LLM의 창대한 가능성을 맛 볼 수 있었다.  
벌써 프로젝트가 끝난 지 벌써 6개월이 넘었고, 그 사이 LLM 기술은 더 빠르게 성장하며 할 수 있는 일도 많아졌다.

앞으로도 재밌는 프로젝트들을 통해 LLM의 가능성을 발굴하고, 이세상에 없던 새로운 서비스를 만들어 더욱 편리한 세상을 만드는 데 기여하고 싶다.
